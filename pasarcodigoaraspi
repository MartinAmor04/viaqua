import argparse
import numpy as np
import librosa
import wave
import subprocess
import io

from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping

# --- CONFIGURACIÓN ---
N_MELS = 128                # Resolución en frecuencia (bandas Mel)
FIXED_FRAMES = 128          # Resolución en tiempo (nº de "ventanas" fijas)
DURATION = 3.0              # Duración de cada muestra en segundos
SAMPLING_RATE = 48000       # Frecuencia de muestreo en Hz
BATCH_AUDIOS = 10           # Muestras por lote de entrenamiento
PERCENTILE_ERR = 95         # Percentil para inicializar err_max con errores de validación

def preprocess_signal(signal):
    """
    Convierte una señal de audio cruda en un espectrograma Mel normalizado.

    Parameters
    ----------
    signal : np.ndarray
        Señal de audio en formato mono, con valores enteros.

    Returns
    -------
    np.ndarray
        Espectrograma Mel normalizado en el rango [0, 1], con forma (N_MELS, FIXED_FRAMES).
    """
    signal = signal.astype(np.float32)
    signal = signal / (np.max(np.abs(signal)) + 1e-6)  # Normalización segura
    S = librosa.feature.melspectrogram(y=signal, sr=SAMPLING_RATE, n_mels=N_MELS)
    S_dB = librosa.power_to_db(S, ref=np.max)

    if S_dB.shape[1] < FIXED_FRAMES:
        pad = FIXED_FRAMES - S_dB.shape[1]
        S_dB = np.pad(S_dB, ((0, 0), (0, pad)), mode='constant')
    else:
        S_dB = S_dB[:, :FIXED_FRAMES]

    mn, mx = S_dB.min(), S_dB.max()
    S_norm = (S_dB - mn) / (mx - mn + 1e-6)
    return S_norm.astype(np.float32)

def record_audio():
    """
    Graba una muestra de audio en tiempo real usando `arecord` y la convierte a un array NumPy.

    Returns
    -------
    np.ndarray
        Señal de audio capturada como arreglo de enteros de 32 bits.
    """
    print("[INFO] Grabando muestra de audio...")
    cmd = [
        'arecord',
        '-D', 'plughw:2',
        '-c1',
        '-r', str(SAMPLING_RATE),
        '-f', 'S32_LE',
        '-t', 'wav',
        '-d', str(int(DURATION)),
        '-q'
    ]
    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE)
    raw_audio = proc.stdout.read()
    proc.wait()

    wav_file = io.BytesIO(raw_audio)
    with wave.open(wav_file, 'rb') as wf:
        frames = wf.readframes(wf.getnframes())
        audio_np = np.frombuffer(frames, dtype=np.int32)
    return audio_np

def autoencoder_model(input_dim):
    """
    Construye un autoencoder denso para detección de anomalías en espectrogramas.

    Parameters
    ----------
    input_dim : int
        Dimensión de entrada (N_MELS * FIXED_FRAMES).

    Returns
    -------
    autoencoder : keras.Model
        Autoencoder completo (input → bottleneck → reconstrucción), compilado con MSE.
    encoder : keras.Model
        Submodelo (input → bottleneck) para extraer vectores latentes.
    """
    inp = Input(shape=(input_dim,), name='encoder_input')
    x = Dense(128, activation='relu', name='enc_dense1')(inp)
    x = Dense(32, activation='relu', name='enc_dense2')(x)
    bottleneck = Dense(16, activation='relu', name='bottleneck')(x)

    x = Dense(32, activation='relu', name='dec_dense1')(bottleneck)
    x = Dense(128, activation='relu', name='dec_dense2')(x)
    decoded = Dense(input_dim, activation='sigmoid', name='decoder_output')(x)

    autoencoder = Model(inputs=inp, outputs=decoded, name='Autoencoder')
    autoencoder.compile(optimizer=Adam(1e-3), loss='mse', metrics=['mae'])

    encoder = Model(inputs=inp, outputs=bottleneck, name='Encoder')
    return autoencoder, encoder

def main():
    """
    Función principal: entrena un autoencoder en tiempo real con audio grabado,
    extrae latentes de validación para inicializar `err_max`, y luego realiza
    inferencia continua filtrando ruidos externos y estimando porcentaje de daño.
    """
    parser = argparse.ArgumentParser()
    parser.add_argument('--batch_size', type=int, default=16,
                        help='Tamaño del batch para entrenamiento.')
    parser.add_argument('--threshold', type=float, default=0.1,
                        help='Umbral de error para detección de anomalías.')
    args = parser.parse_args()

    input_dim = N_MELS * FIXED_FRAMES
    autoencoder, encoder = autoencoder_model(input_dim)

    valid_latents_list = []  # Para almacenar latentes de validación
    valid_X_list = []        # Para almacenar X_val de cada época, y luego calcular errores
    umbral = args.threshold

    print('[INFO] Entrenando hasta que val_loss sea menor que', umbral, '...')
    epoch_idx = 0
    while True:
        # 1) Recolectar BATCH_AUDIOS ejemplos en tiempo real
        X_batch = []
        for _ in range(BATCH_AUDIOS):
            sig = record_audio()
            feat = preprocess_signal(sig).flatten()
            X_batch.append(feat)
        X_batch = np.array(X_batch)

        # 2) Separar en entrenamiento y validación
        X_train, X_val = train_test_split(X_batch, test_size=0.2, random_state=42)

        # 3) Entrenar con early stopping
        early = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True, verbose=1)
        history = autoencoder.fit(
            X_train, X_train,
            validation_data=(X_val, X_val),
            epochs=10,
            batch_size=args.batch_size,
            verbose=2,
            callbacks=[early]
        )

        # 4) Tomar la mejor época (mínima val_loss dentro de estas 10)
        best_epoch = np.argmin(history.history['val_loss'])
        val_loss = history.history['val_loss'][best_epoch]
        loss    = history.history['loss'][best_epoch]
        mae     = history.history['mae'][best_epoch]
        epoch_idx += 1
        print(f'Época {epoch_idx}, mejor en sub-época {best_epoch+1} → '
              f'loss: {loss:.6f}, val_loss: {val_loss:.6f}, mae: {mae:.6f}')

        # 5) Guardar latentes de X_val y también X_val para posterior cálculo de errores
        lat_val = encoder.predict(X_val, verbose=0)
        valid_latents_list.append(lat_val)
        valid_X_list.append(X_val)

        # 6) Comprobar umbral de parada
        if val_loss < umbral:
            print('[INFO] Umbral alcanzado. Pasando a predicción...')
            break

    # ——————————————————————————————————————————————
    #  CÁLCULO DE `radio_motor` Y `err_max` INICIAL SOBRE VALIDACIÓN
    # ——————————————————————————————————————————————

    # 1) Concatenar todos los latentes de validación
    valid_latents = np.vstack(valid_latents_list)  # shape = (N_total_valid, 16)
    centroid = np.mean(valid_latents, axis=0)      # vector (16,)

    # 2) Distancias desde cada latente al centroid
    distancias = np.linalg.norm(valid_latents - centroid[np.newaxis, :], axis=1)

    # 3) Definir radio_base como percentil alto de esas distancias
    percentil = 99
    radio_base = np.percentile(distancias, percentil)
    radio_motor = radio_base * 1.10  # +10% de margen

    print(f"\n[INFO] Centroide (espacio latente): {centroid}")
    print(f"[INFO] Radio base (percentil {percentil}): {radio_base:.5f}")
    print(f"[INFO] Radio final con margen (radio_motor): {radio_motor:.5f}\n")

    # 4) Concatenar todos los X_val para calcular sus errores de reconstrucción
    valid_X = np.vstack(valid_X_list)  # shape = (N_total_valid, input_dim)
    rec_valid = autoencoder.predict(valid_X, verbose=0)
    err_vals = np.mean((valid_X - rec_valid) ** 2, axis=1)  # MSE por muestra

    # 5) Inicializar err_max al percentil PERCENTILE_ERR de esos errores
    err_max_init = np.percentile(err_vals, PERCENTILE_ERR)
    err_max = float(err_max_init)
    print(f"[INFO] MSEs de validación (percentil {PERCENTILE_ERR}): {err_max:.5f}\n")

    # 6) Umbral para “filtro externo” (se puede ajustar según pruebas)
    err_filtro_externo = umbral * 1.2

    print('[INFO] Iniciando predicción con filtro combinado de latente + reconstrucción')
    print(f'       radio_motor = {radio_motor:.5f}, err_max_init = {err_max:.5f}, err_filtro_externo = {err_filtro_externo:.5f}\n')

    # ————————————————————————
    #  BUCLE DE INFERENCIA CONTINUA
    # ————————————————————————
    while True:
        # 1) Grabar y preprocesar
        s = record_audio()
        feat = preprocess_signal(s).flatten()[np.newaxis, ...]  # (1, input_dim)

        # 2) Proyectar al espacio latente y medir distancia
        z = encoder.predict(feat, verbose=0)[0]  # (16,) latente
        dist = np.linalg.norm(z - centroid)

        # 3a) Caso “latente dentro del radio” → motor (sano o con fallo leve)
        if dist <= radio_motor:
            rec = autoencoder.predict(feat, verbose=0)
            err = float(np.mean((feat - rec) ** 2))

            # Actualiza err_max si aparece un error mayor
            if err > err_max:
                err_max = err
                print(f'[CALIB] Nuevo err_max = {err_max:.5f}')

            # Calcular % de daño
            if err <= umbral:
                pct = 0.0
            else:
                denom = max(err_max - umbral, 1e-6)
                pct = np.clip((err - umbral) / denom, 0, 1) * 100

            print(f'[MOTOR] dist={dist:.5f} ≤ {radio_motor:.5f}, Error={err:.5f}, Daño={pct:6.2f}%\n')
            continue

        # 3b) Caso “latente fuera del radio”: ruido externo o motor muy roto
        rec = autoencoder.predict(feat, verbose=0)
        err = float(np.mean((feat - rec) ** 2))

        # 3b.1) Si err está por debajo de err_filtro_externo → RUÍDO EXTERNO → descartar
        if err <= err_filtro_externo:
            print(f'[FILTRO] dist={dist:.5f} > {radio_motor:.5f} y err={err:.5f} ≤ {err_filtro_externo:.5f} → RUÍDO EXTERNO\n')
            continue

        # 3b.2) Si err > err_filtro_externo → MOTOR MUY DAÑADO
        if err > err_max:
            err_max = err
            print(f'[CALIB] Nuevo err_max = {err_max:.5f}')

        denom = max(err_max - umbral, 1e-6)
        pct = np.clip((err - umbral) / denom, 0, 1) * 100
        print(f'[MOTOR DAÑADO] dist={dist:.5f} > {radio_motor:.5f}, Error={err:.5f}, Daño={pct:6.2f}%\n')

if __name__ == '__main__':
    main()
